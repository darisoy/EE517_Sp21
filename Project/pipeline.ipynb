{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "EE 517: Project pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darisoy/EE517_Sp21/blob/master/Project/pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eQCgMJ3HVCz"
      },
      "source": [
        "# Set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mek_yYjHDLG"
      },
      "source": [
        "# install packages\n",
        "%%capture\n",
        "!pip install allennlp\n",
        "!pip install allennlp-models\n",
        "!pip install spacy-dbpedia-spotlight\n",
        "!pip install gender-guesser\n",
        "\n",
        "import spacy\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "import spacy_dbpedia_spotlight\n",
        "import gender_guesser.detector as gender"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwffFN3Icgrf"
      },
      "source": [
        "# initialize models\n",
        "%%capture\n",
        "!python -m spacy download en_core_web_lg\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "allen_model_url = 'https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz'\n",
        "allen_predictor = Predictor.from_path(allen_model_url)  # load the model\n",
        "nel = spacy_dbpedia_spotlight.create('en')\n",
        "genDec = gender.Detector()"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao4OtUgPp3Dw"
      },
      "source": [
        "#list of person mentions that are not names\n",
        "fem_p = ['she', 'her', 'hers', 'herself']\n",
        "male_p = ['he', 'him', 'his', 'himself']\n",
        "personal_p = ['i', 'me', 'we', 'us', 'myself', 'ourself', 'ourselves']\n",
        "other_p = ['they', 'them', 'their', 'you', 'themself', 'themselves']\n",
        "people = ['adult','adults', 'person','people','child','children']\n",
        "\n",
        "person_f_singular = ['girl','woman','mrs','ms','mother','mom','aunt','niece','sister','wife','daughter','grandmother','grandma','grandmom','granddaughter','bride','girlfriend','gal','madam','lady']\n",
        "person_m_singular = ['boy','man','mr','father','dad','uncle','nephew','brother','husband','son','grandfather','grandpa','granddad','grandson','groom','boyfriend','guy','gentleman','bachelor']\n",
        "people_f_plural = ['girls','women','mothers','moms','aunts','nieces','sisters','wives','daughters','grandmothers','grandmas','granddaughters','brides','girlfriends','gals','ladies']\n",
        "people_m_plural = ['boys','men','fathers','dads','uncles','nephews','brothers','husbands','sons','grandfathers','grandpas','grandsons','grooms','boyfriends','guys','gentlemen','bachelors']\n",
        "people_f = person_f_singular + people_f_plural\n",
        "people_m = person_m_singular + people_m_plural\n",
        "\n",
        "un_named_mentions = fem_p + male_p + personal_p + other_p + people + people_f + people_m\n",
        "f_un_named = fem_p + people_f\n",
        "m_un_named = male_p + people_m\n",
        "neutral_un_named = personal_p + other_p + people"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPj_y-xBUnUx"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcGLEDtMVHJ0"
      },
      "source": [
        "# run text through models\n",
        "\n",
        "def get_coref(text, predictor):\n",
        "    prediction = predictor.predict(document=text)\n",
        "    return prediction['clusters'], prediction['document']\n",
        "\n",
        "def get_ner(text, nlp):\n",
        "    return [[ent.start, ent.end-1] for ent in nlp(text).ents if ent.label_ == 'PERSON']\n",
        "\n",
        "def get_nel(text, nel):\n",
        "    threshold = 0.95\n",
        "    return [[ent.start, ent.end-1] for ent in nel(text).ents if float(ent._.dbpedia_raw_result['@similarityScore']) >= threshold]\n",
        "\n",
        "def get_gender(person_mention):\n",
        "    if person_mention.lower() in un_named_mentions:\n",
        "        if person_mention.lower() in f_un_named:\n",
        "            return 'F'\n",
        "        elif person_mention.lower() in m_un_named:\n",
        "            return 'M'\n",
        "    else:\n",
        "        first_name = person_mention.split()[0]\n",
        "        gen_name = genDec.get_gender(first_name.capitalize())\n",
        "        if 'female' in gen_name:\n",
        "            return 'F'\n",
        "        elif 'male' in gen_name:\n",
        "            return 'M'\n",
        "    return '-'\n",
        "\n",
        "def get_pronouns(dic):\n",
        "    result = []\n",
        "    for i, word in enumerate(dic):\n",
        "        if word.lower() in un_named_mentions:\n",
        "            result.append([i, i])\n",
        "    return result"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsOV3OBUnjZZ"
      },
      "source": [
        "# converting spans to text\n",
        "\n",
        "def span_to_string(span, dic):\n",
        "    [a, b] = span\n",
        "    return \" \".join(dic[a:b+1])\n",
        "\n",
        "def array_to_text(array, dic):\n",
        "    return [span_to_string(e, dic) for e in array]\n",
        "\n",
        "def array2d_to_text(array2D, dic):\n",
        "    return [array_to_text(arr, dic) for arr in array2D]"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDhS0Ov5faHy"
      },
      "source": [
        "# get hypo & histo from model results\n",
        "\n",
        "def get_cluster(person, clusters):\n",
        "    for i, cluster in enumerate(clusters):\n",
        "        if person in cluster:\n",
        "            return clusters[i]\n",
        "    return [person]\n",
        "\n",
        "def split_hist_hypo(clusters, person_mentions, famous_people, gender):\n",
        "    historical = []\n",
        "    hypothetical = []\n",
        "    for i, person in enumerate(person_mentions):\n",
        "        # skip if not gendered\n",
        "        if gender[i] == '-':\n",
        "            continue\n",
        "        # skip if already in one of the lists\n",
        "        in_historical = any(person in sublist for sublist in historical)\n",
        "        in_hypothetical = any(person in sublist for sublist in hypothetical)\n",
        "        if in_historical or in_hypothetical:\n",
        "            continue\n",
        "        # add the cluster to correct list\n",
        "        person_set = get_cluster(person, clusters)\n",
        "        if any(p in person_set for p in famous_people):\n",
        "            historical.append(person_set)\n",
        "        else:\n",
        "            hypothetical.append(person_set)\n",
        "    return historical, hypothetical"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dIb0xPzZcZK"
      },
      "source": [
        "# pipline main function\n",
        "def get_hist_hypo_references(text, nlp, nel, debug=False):\n",
        "    doc = nlp(text)\n",
        "    clusters, dic = get_coref(text, allen_predictor)\n",
        "    person_mentions = get_ner(text, nlp) + get_pronouns(dic)\n",
        "    gender = [get_gender(span_to_string(p, dic)) for p in person_mentions]\n",
        "    famous_people = get_nel(text, nel)\n",
        "    hist, hypo = split_hist_hypo(clusters, person_mentions, famous_people, gender)\n",
        "    hist = array2d_to_text(hist, dic)\n",
        "    hypo = array2d_to_text(hypo, dic)\n",
        "    if debug and len(person_mentions) > 0:\n",
        "        print('***NEW SENTENCE***\\t\\t %s' % text)\n",
        "        print()\n",
        "        print('Coreference Model Output\\t %s' % array2d_to_text(clusters, dic))\n",
        "        print('NER + Pronouns Output\\t\\t %s' % array_to_text(person_mentions, dic))\n",
        "        print('Gender Guesser Output\\t\\t %s' % gender)\n",
        "        print('NEL Output\\t\\t\\t %s' % array_to_text(famous_people, dic,))\n",
        "        print()\n",
        "        print('Historical references\\t\\t %s' % hist)\n",
        "        print('Hypothetical references\\t\\t %s' % hypo)\n",
        "        print()\n",
        "        print()\n",
        "    return hist, hypo"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehhkjavYGO5r",
        "outputId": "be797100-b139-42fb-e4fa-9a62c6e5cc14"
      },
      "source": [
        "sample = 'Albert Einstein didn\\'t want his friend Jenny to feel lonely so they invited her to the party. Tom is happy.'\n",
        "hist, hypo = get_hist_hypo_references(sample, nlp, nel, debug=True)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***NEW SENTENCE***\t\t Albert Einstein didn't want his friend Jenny to feel lonely so they invited her to the party. Tom is happy.\n",
            "\n",
            "Coreference Model Output\t [['Albert Einstein', 'his'], ['his friend Jenny', 'her']]\n",
            "NER + Pronouns Output\t\t ['Albert Einstein', 'Jenny', 'Tom', 'his', 'they', 'her']\n",
            "Gender Guesser Output\t\t ['M', 'F', 'M', 'M', '-', 'F']\n",
            "NEL Output\t\t\t ['Albert Einstein']\n",
            "\n",
            "Historical references\t\t [['Albert Einstein', 'his']]\n",
            "Hypothetical references\t\t [['Jenny'], ['Tom'], ['his friend Jenny', 'her']]\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9B1orA3G6NF"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB2dutoaHroM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "54d0b74a-a74d-4e57-e33f-34e647dd6997"
      },
      "source": [
        "import pandas as pd\n",
        "d_all1 = pd.read_csv('/content/train.csv', delimiter= \",\", low_memory=False, index_col=0)\n",
        "d_all2 = pd.read_csv('/content/test.csv', delimiter= \",\", low_memory=False, index_col=0)\n",
        "d_all1 = d_all1.drop(['bool'], axis=1)\n",
        "assert all(d_all1.columns == d_all2.columns)\n",
        "d = pd.concat([d_all1, d_all2], axis = 0)\n",
        "d.fillna('[]',inplace = True)\n",
        "d[d.grade=='12'].head()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book</th>\n",
              "      <th>grade</th>\n",
              "      <th>level</th>\n",
              "      <th>science</th>\n",
              "      <th>text</th>\n",
              "      <th>text_org</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Gr12_PhysicalSciences_Learner_Eng.txt3</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>sponsor this textbook was developed with corp...</td>\n",
              "      <td>SPONSOR This textbook was developed with corp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Gr12_PhysicalSciences_Learner_Eng.txt3</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>well structured , impactful corporate social ...</td>\n",
              "      <td>Well structured, impactful Corporate Social I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gr12_PhysicalSciences_Learner_Eng.txt3</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>the merger between metropolitan and momentum ...</td>\n",
              "      <td>The merger between Metropolitan and Momentum ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Gr12_PhysicalSciences_Learner_Eng.txt3</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>hiv/aids is becoming a manageable disease in ...</td>\n",
              "      <td>HIV/AIDS is becoming a manageable disease in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Gr12_PhysicalSciences_Learner_Eng.txt3</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>momentum 's focus on persons with disabilitie...</td>\n",
              "      <td>Momentum's focus on persons with disabilities...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     book  ...                                           text_org\n",
              "5  Gr12_PhysicalSciences_Learner_Eng.txt3  ...   SPONSOR This textbook was developed with corp...\n",
              "6  Gr12_PhysicalSciences_Learner_Eng.txt3  ...   Well structured, impactful Corporate Social I...\n",
              "7  Gr12_PhysicalSciences_Learner_Eng.txt3  ...   The merger between Metropolitan and Momentum ...\n",
              "8  Gr12_PhysicalSciences_Learner_Eng.txt3  ...   HIV/AIDS is becoming a manageable disease in ...\n",
              "9  Gr12_PhysicalSciences_Learner_Eng.txt3  ...   Momentum's focus on persons with disabilities...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjZfesUaMcPN",
        "outputId": "a1cc81e2-2511-49c3-a61a-3919a50b940d"
      },
      "source": [
        "for text in d[d.grade=='12'].text_org:\n",
        "    hist, hypo = get_hist_hypo_references(text, nlp, nel, debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***NEW SENTENCE***\t\t  Well structured, impactful Corporate Social Investment (CSI) has the ability to contribute positively to nation building and drive positive change in the communities. MMI's commitment to social investment means that we are constantly looking for ways in which we can assist some of South Africa's most vulnerable citizens to expand their horizons and gain greater access to life's opportunities. This means that we do not view social investment as a nice to have or as an exercise in marketing or sponsorship but rather as a critical part of our contribution to society.\n",
            "\n",
            "Coreference Model Output\t [[\"some of South Africa 's most vulnerable citizens\", 'their']]\n",
            "NER + Pronouns Output\t\t ['we', 'we', 'their', 'we']\n",
            "Gender Guesser Output\t\t ['-', '-', '-', '-']\n",
            "NEL Output\t\t\t ['South Africa']\n",
            "\n",
            "Historical references\t\t []\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  HIV/AIDS is becoming a manageable disease in many developed countries but in a country such as ours, it remains a disease where people are still dying of this scourge unnecessarily. Metropolitan continues to make a difference in making sure that HIV AIDS moves away from being a death sentence to a manageable disease. Metropolitan's other focus area is education which remains the key to economic prosperity for our country.\n",
            "\n",
            "Coreference Model Output\t [['HIV / AIDS', 'it', 'this scourge', 'HIV AIDS'], ['Metropolitan', \"Metropolitan 's\"], ['ours', 'our country']]\n",
            "NER + Pronouns Output\t\t ['people']\n",
            "Gender Guesser Output\t\t ['-']\n",
            "NEL Output\t\t\t ['AIDS', 'AIDS']\n",
            "\n",
            "Historical references\t\t []\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  Momentum's focus on persons with disabilities ensures that this community is included and allowed to make their contribution to society. Orphaned and vulnerable children are another focus area for Momentum and projects supported ensure that children are allowed to grow up safely, to assume their role along with other children in inheriting a prosperous future.\n",
            "\n",
            "Coreference Model Output\t [['persons with disabilities', 'this community', 'their'], [\"Momentum 's\", 'Momentum'], ['children', 'their']]\n",
            "NER + Pronouns Output\t\t ['their', 'children', 'children', 'their', 'children']\n",
            "Gender Guesser Output\t\t ['-', '-', '-', '-', '-']\n",
            "NEL Output\t\t\t ['Momentum', 'Momentum']\n",
            "\n",
            "Historical references\t\t []\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  MOBILE & TABLET MOBI You can access this whole textbook on your mobile phone. Yes, the whole thing, anytime, anywhere. Visit the mobi sites at:  and   MXIT Don't stress if you haven't got a smart phone. All Mxit users can read their Everything Series textbooks on Mxit Reach too. Add Everything Maths and Everything Science as Mxit contacts or browse to the books on Mxit Reach. mxit>tradepost>reach>education> everything maths or everything science DOWNLOAD FOR TABLETS You can download a digital copy of the Everything Series textbooks for reading on your PC, tablet, iPad and Kindle.  and  PRACTISE INTELLIGENTLY PRACTISE FOR TESTS & EXAMS ONLINE & ON YOUR PHONE To do well in tests and exams you need practice, but knowing where to start and getting past exams papers can be difficult.\n",
            "\n",
            "Coreference Model Output\t [['this whole textbook', 'the whole thing'], ['MXIT', 'Mxit', 'Mxit', 'mxit'], ['All Mxit users', 'their'], ['Mxit Reach', 'Mxit Reach'], ['their Everything Series textbooks', 'the Everything Series textbooks']]\n",
            "NER + Pronouns Output\t\t ['You', 'you', 'their', 'You', 'you']\n",
            "Gender Guesser Output\t\t ['-', '-', '-', '-', '-']\n",
            "NEL Output\t\t\t ['MOBI', 'mobile phone', 'MXIT', 'smart phone', 'Mxit', 'Mxit', 'Mxit', 'Mxit', 'mxit', 'digital', 'iPad', 'Kindle']\n",
            "\n",
            "Historical references\t\t []\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  Intelligent Practice is an online Maths and Science practice service that allows you to practise questions at the right level of difficulty for you and get your answers checked instantly!\n",
            "\n",
            "Coreference Model Output\t []\n",
            "NER + Pronouns Output\t\t ['you', 'you']\n",
            "Gender Guesser Output\t\t ['-', '-']\n",
            "NEL Output\t\t\t []\n",
            "\n",
            "Historical references\t\t []\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  YOUR DASHBOARD Your individualised dashboard on Intelligent Practice helps you keep track of your work. Your can check your progress and mastery for every topic in the book and use it to help you to manage your studies and target your weaknesses. You can also use your dashboard to show your teachers, parents, universities or bursary institutions what you have done during the year.\n",
            "\n",
            "Coreference Model Output\t [['Your individualised dashboard on Intelligent Practice', 'it', 'your dashboard']]\n",
            "NER + Pronouns Output\t\t ['you', 'you', 'You', 'you']\n",
            "Gender Guesser Output\t\t ['-', '-', '-', '-']\n",
            "NEL Output\t\t\t []\n",
            "\n",
            "Historical references\t\t []\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  In this chapter you will learn how to gather evidence using the scientific method.\n",
            "\n",
            "Coreference Model Output\t []\n",
            "NER + Pronouns Output\t\t ['you']\n",
            "Gender Guesser Output\t\t ['-']\n",
            "NEL Output\t\t\t ['scientific method']\n",
            "\n",
            "Historical references\t\t []\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  The most important, and most exciting, thing about science and scientific theories is that they are not fixed. Hypotheses are formed and carefully tested, leading to scientific theories that explain those observations and predict results. The results are not made to fit the hypotheses. If new information comes to light with the use of better equipment, or the results of other experiments, this new information is used to improve and expand current theories. If a theory is found to have been incorrect it is changed to fit this new information. The data should never be made to fit the theory, if the data does not fit the theory then the theory is reworked or discarded. Although this changing of opinion is often taken for inconsistency, it is this very willingness to adapt that makes science useful, and allows new discoveries to be made. Remember that the term theory has a different meaning in science. A scientific theory is not like your theory of about why you can only ever find one sock. A scientific theory is one that has been tested and proven through repeated experiment and data. Scientists are constantly testing the data available, as well as commonly held beliefs, and it is this constant testing that allows progress, and improved theories.\n",
            "\n",
            "Coreference Model Output\t [['science and scientific theories', 'they'], ['Hypotheses', 'the hypotheses'], ['new information', 'this new information', 'this new information'], ['a theory', 'it', 'the theory', 'the theory', 'the theory'], ['The data', 'the data']]\n",
            "NER + Pronouns Output\t\t ['they', 'you']\n",
            "Gender Guesser Output\t\t ['-', '-']\n",
            "NEL Output\t\t\t ['scientific theory', 'scientific theory']\n",
            "\n",
            "Historical references\t\t []\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  The theory of gravity has been slowly developing since the beginning of the 16th century. Galileo Galilei is credited with some of the earliest work. At the time it was widely believed that heavier objects accelerated faster toward the earth than light objects did. Galileo had a hypothesis that this was not true, and performed experiments to prove this. Galileo's work allowed Sir Isaac Newton to hypothesise not only a theory of gravity on earth, but that gravity is what held the planets in their orbits. Newton's theory was used by John Couch Adams and Urbain Le Verrier to predict the planet Neptune in the solar system and this prediction was proved experimentally when Neptune was discovered by Johann Gottfried Galle.\n",
            "\n",
            "Coreference Model Output\t [['Galileo Galilei', 'Galileo', \"Galileo 's\"], ['accelerated', 'this', 'this'], ['the earth', 'earth'], ['the planets', 'their'], ['Sir Isaac Newton', \"Newton 's\"], ['predict', 'this prediction'], ['the planet Neptune in the solar system', 'Neptune']]\n",
            "NER + Pronouns Output\t\t ['Isaac Newton', 'John Couch Adams', 'Urbain Le Verrier', 'Johann Gottfried Galle', 'their']\n",
            "Gender Guesser Output\t\t ['M', 'M', 'M', 'M', '-']\n",
            "NEL Output\t\t\t ['gravity', 'Galileo Galilei', 'Galileo', 'Galileo', 'Isaac Newton', 'gravity', 'gravity', 'Newton', 'John Couch Adams', 'Urbain Le Verrier', 'planet', 'Neptune', 'solar system', 'Neptune', 'Johann Gottfried Galle']\n",
            "\n",
            "Historical references\t\t [['Isaac Newton'], ['John Couch Adams'], ['Urbain Le Verrier'], ['Johann Gottfried Galle']]\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  Although a large majority of gravitational motion could be explained by Newton's theory of gravity, there were things that did not fit. But although a newer theory that better fits the facts was eventually proved by Albert Einstein, Newton's gravitational theory is still successfully used in many applications where the masses, speeds and energies are not too large.\n",
            "\n",
            "Coreference Model Output\t [[\"Newton 's\", \"Newton 's\"], [\"Newton 's theory of gravity\", \"Newton 's gravitational theory\"]]\n",
            "NER + Pronouns Output\t\t ['Albert Einstein']\n",
            "Gender Guesser Output\t\t ['M']\n",
            "NEL Output\t\t\t ['gravitational motion', 'Newton', 'gravity', 'Albert Einstein', 'Newton', 'gravitational']\n",
            "\n",
            "Historical references\t\t [['Albert Einstein']]\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  The principles of the three rules of thermodynamics describe how energy works, on all size levels (from the workings of the Earth's core, to a car engine). The basis for these three rules started as far back as 1650 with Otto von Guericke. He had a hypothesis that a vacuum pump could be made, and proved this by making one. In 1656 Robert Boyle and Robert Hooke used this information and built an air pump. Over the next 150 years the theory was expanded on and improved. Denis Papin built a steam pressuriser and release valve, and designed a piston cylinder and engine, which Thomas Savery and Thomas Newcomen built. These engines inspired the study of heat capacity and latent heat. Joseph Black and James Watt increased the steam engine efficiency and it was their work that Sadi Carnot (considered the father of thermodynamics) studied before publishing a discourse on heat, power, energy and engine efficiency in 1824. This work by Carnot was the beginning of modern thermodynamics as a science, with the first thermodynamics textbook written in 1859, and the first and second laws of thermodynamics being determined in the 1850s. Scientists such as Lord Kelvin, Max Planck, J. Willard Gibbs (all names you should recognise) among many many others studied thermodynamics. Over the course of 350 years thermodynamics has developed from the building of a vacuum pump, to some of the most important fundamental laws of energy.\n",
            "\n",
            "Coreference Model Output\t [['the three rules of thermodynamics', 'these three rules'], ['Otto von Guericke', 'He'], ['a hypothesis that a vacuum pump could be made', 'this', 'this information'], ['a piston cylinder and engine , which Thomas Savery and Thomas Newcomen built', 'These engines'], ['Joseph Black and James Watt', 'their'], ['a discourse on heat , power , energy and engine efficiency', 'This work by Carnot'], ['Sadi Carnot ( considered the father of thermodynamics )', 'Carnot']]\n",
            "NER + Pronouns Output\t\t ['Otto von Guericke', 'Robert Boyle', 'Robert Hooke', 'Denis Papin', 'Thomas Savery', 'Thomas Newcomen', 'Joseph Black', 'James Watt', 'Sadi Carnot', 'Carnot', 'Kelvin', 'Max Planck', 'J. Willard Gibbs', 'He', 'their', 'father', 'you']\n",
            "Gender Guesser Output\t\t ['M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', '-', 'M', 'M', '-', 'M', '-', 'M', '-']\n",
            "NEL Output\t\t\t ['Earth', 'Otto von Guericke', 'vacuum pump', 'Robert Boyle', 'Robert Hooke', 'air pump', 'Denis Papin', 'valve', 'piston', 'Thomas Savery', 'Thomas Newcomen', 'heat capacity', 'latent heat', 'James Watt', 'steam engine', 'Carnot', 'Lord Kelvin', 'Max Planck', 'Willard', 'vacuum pump']\n",
            "\n",
            "Historical references\t\t [['Otto von Guericke', 'He'], ['Robert Boyle'], ['Robert Hooke'], ['Denis Papin'], ['Thomas Savery'], ['Thomas Newcomen'], ['James Watt'], ['Max Planck']]\n",
            "Hypothetical references\t\t [['Joseph Black'], ['Sadi Carnot'], ['Kelvin'], ['father']]\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  FACT Robert Boyle should be a familiar name to you. Boyle's law came about from his air pump experiments, where he discovered that pressure is inversely proportional to volume at a constant temperature (p 1 at constant T).\n",
            "\n",
            "Coreference Model Output\t [['Robert Boyle', 'his', 'he']]\n",
            "NER + Pronouns Output\t\t ['FACT Robert Boyle', 'Boyle', 'you', 'his', 'he']\n",
            "Gender Guesser Output\t\t ['-', '-', '-', 'M', 'M']\n",
            "NEL Output\t\t\t ['Robert Boyle']\n",
            "\n",
            "Historical references\t\t [['Robert Boyle', 'his', 'he']]\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n",
            "***NEW SENTENCE***\t\t  The scientific method is the basic skill process in the world of science. Since the beginning of time humans have been curious as to why and how things happen in the world around us. The scientific method provides scientists with a well structured scientific platform to help find the answers to their questions. Using the scientific method there is no limit as to what we can investigate. The scientific method can be summarised as follows: 1. Ask a question about the world around you. 2. Do background research on your questions. 3. Make a hypothesis about the event that gives a sensible result. You must be able to test your hypothesis through experiment. 4. Design an experiment to test the hypothesis. These methods must be repeatable and follow a logical approach. 5. Collect data accurately and interpret the data. You must be able to take measurements, collect information, and present your data in a useful format (drawings, explanations, tables and graphs). 6. Draw conclusions from the results of the experiment. Your observations must be made objectively, never force the data to fit your hypothesis. 7. Decide whether your hypothesis explains the data collected accurately. 8. If the data fits your hypothesis, verify your results by repeating the experiment or getting someone else to repeat the experiment. 9. If your data does not fit your hypothesis perform more background research and FACT In science we never 'prove' a hypothesis through a single experiment because there is a chance that you made an error somewhere along the way. What you can say is that your results SUPPORT the original hypothesis.\n",
            "\n",
            "Coreference Model Output\t [['humans', 'us'], ['The scientific method', 'The scientific method', 'the scientific method', 'The scientific method'], ['scientists', 'their'], ['a hypothesis about the event that gives a sensible result', 'your hypothesis', 'the hypothesis', 'the original hypothesis'], ['data', 'the data'], ['your hypothesis', 'your hypothesis'], ['the data', 'the data'], ['the experiment', 'the experiment'], ['your hypothesis', 'your hypothesis']]\n",
            "NER + Pronouns Output\t\t ['us', 'their', 'we', 'you', 'You', 'You', 'we', 'you', 'you']\n",
            "Gender Guesser Output\t\t ['-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
            "NEL Output\t\t\t ['scientific method', 'scientific method', 'scientific method', 'scientific method', 'FACT']\n",
            "\n",
            "Historical references\t\t []\n",
            "Hypothetical references\t\t []\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhwSyqxsz_LB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}