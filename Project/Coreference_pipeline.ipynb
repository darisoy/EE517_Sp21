{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Huggingface Neuralcoref and small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile neuralcoref from scratch according to https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.6\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print(spacy.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "spacy.strings.StringStore size changed, may indicate binary incompatibility. Expected 88 from C header, got 64 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4d33cbd9a6ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_lg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Add neural coref to SpaCy's pipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mneuralcoref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_lg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuralcoref/neuralcoref/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spacy.strings.StringStore size changed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneuralcoref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuralcoref\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuralCoref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m from neuralcoref.file_utils import (\n\u001b[1;32m     12\u001b[0m     \u001b[0mNEURALCOREF_MODEL_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mneuralcoref.pyx\u001b[0m in \u001b[0;36minit neuralcoref.neuralcoref\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: spacy.strings.StringStore size changed, may indicate binary incompatibility. Expected 88 from C header, got 64 from PyObject"
     ]
    }
   ],
   "source": [
    "import en_core_web_lg\n",
    "# Add neural coref to SpaCy's pipe\n",
    "import neuralcoref\n",
    "\n",
    "nlp = en_core_web_lg.load()\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc = nlp(\"Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party. Tom is happy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eva and Martha: [Eva and Martha, their, they], Jenny: [Jenny, her]]\n"
     ]
    }
   ],
   "source": [
    "#doc._.has_coref\n",
    "print(doc._.coref_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 2], [6, 6], [13, 13]], [[8, 8], [15, 15]]]\n",
      "[Eva and Martha: [Eva and Martha, their, they], Jenny: [Jenny, her]]\n"
     ]
    }
   ],
   "source": [
    "all_clusters = []\n",
    "for cluster in doc._.coref_clusters:\n",
    "    cluster_start_end = []\n",
    "    for mention in cluster.mentions:\n",
    "        cluster_start_end.append([mention.start, mention.end -1])\n",
    "    all_clusters.append(cluster_start_end)\n",
    "print(all_clusters)\n",
    "print(doc._.coref_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up AllenNLP coreference resolution and small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install allennlp\n",
    "#!pip install allennlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = 'https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz'\n",
    "predictor = Predictor.from_path(model_url)  # load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party. Tom is happy.He says.\"\n",
    "prediction = predictor.predict(document=text)  # get the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters_allen_nlp(prediction):\n",
    "    clusters = []\n",
    "    for cluster in prediction['clusters']:\n",
    "        print(\"cluster\", cluster)\n",
    "        first_mention = \"\"\n",
    "        mention_ref = {}\n",
    "        for token in cluster:\n",
    "            token_start = token[0]\n",
    "            token_end = token[1]\n",
    "            mention = \" \".join(prediction['document'][token_start:token_end + 1])\n",
    "            if first_mention == \"\":\n",
    "                first_mention = mention\n",
    "                mention_ref[first_mention] = [first_mention]\n",
    "            else:\n",
    "                mention_ref[first_mention] += [mention]\n",
    "        print(mention_ref)\n",
    "        clusters.append(mention_ref)\n",
    "        \n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster [[0, 2], [6, 6], [13, 13]]\n",
      "{'Eva and Martha': ['Eva and Martha', 'their', 'they']}\n",
      "cluster [[6, 8], [15, 15]]\n",
      "{'their friend Jenny': ['their friend Jenny', 'her']}\n",
      "cluster [[20, 20], [24, 24]]\n",
      "{'Tom': ['Tom', 'He']}\n",
      "[{'Eva and Martha': ['Eva and Martha', 'their', 'they']}, {'their friend Jenny': ['their friend Jenny', 'her']}, {'Tom': ['Tom', 'He']}]\n"
     ]
    }
   ],
   "source": [
    "clusters_allennlp = get_clusters_allen_nlp(prediction)\n",
    "print(clusters_allennlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER and small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party. Tom is happy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_found = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eva', 'Martha', 'Jenny', 'Tom']\n"
     ]
    }
   ],
   "source": [
    "print(person_found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with textbook data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/spacy/util.py:717: UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the \"spacy_version\" in your meta.json to a version range, with a lower and upper pin. For example: >=3.0.6,<3.1.0\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sys, os, re\n",
    "from IPython import embed\n",
    "from pprint import pprint\n",
    "import string\n",
    "from random import shuffle\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import en_core_web_lg\n",
    "import inflect\n",
    "from subject_object_extraction import *\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "import textacy\n",
    "from textacy.extract import subject_verb_object_triples as extractSVOs\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import ast\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "  \n",
    "d = gender.Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33575"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all1 = pd.read_csv('textbook_data/new_chapter_train_set_gender.csv', delimiter= \",\", low_memory=False, index_col=0)\n",
    "d_all2 = pd.read_csv('textbook_data/new_chapter_test_set_gender.csv', delimiter= \",\", low_memory=False, index_col=0)\n",
    "d_all1 = d_all1.drop(['bool'], axis=1)\n",
    "assert all(d_all1.columns == d_all2.columns)\n",
    "d_all = pd.concat([d_all1, d_all2], axis = 0)\n",
    "d_all.fillna('[]',inplace = True)\n",
    "len(d_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>grade</th>\n",
       "      <th>level</th>\n",
       "      <th>science</th>\n",
       "      <th>text</th>\n",
       "      <th>text_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K_ck12.txt</td>\n",
       "      <td>K_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>we cannot see the wind but we can feel it . t...</td>\n",
       "      <td>We cannot see the wind but we can feel it. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K_ck12.txt</td>\n",
       "      <td>K_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yesterday it rained . there was a lot of wind...</td>\n",
       "      <td>Yesterday it rained. There was a lot of wind....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K_ck12.txt</td>\n",
       "      <td>K_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>summer is here ! july is sunny and hot . summ...</td>\n",
       "      <td>Summer is here! July is sunny and hot. Summer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K_ck12.txt</td>\n",
       "      <td>K_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>it 's starting to cool down from the summer h...</td>\n",
       "      <td>It's starting to cool down from the summer he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K_ck12.txt</td>\n",
       "      <td>K_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the wind pushes the kite high into the sky . ...</td>\n",
       "      <td>The wind pushes the kite high into the sky. W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         book grade  level  science  \\\n",
       "1  K_ck12.txt   K_1      0        1   \n",
       "2  K_ck12.txt   K_1      0        1   \n",
       "3  K_ck12.txt   K_1      0        1   \n",
       "4  K_ck12.txt   K_1      0        1   \n",
       "5  K_ck12.txt   K_1      0        1   \n",
       "\n",
       "                                                text  \\\n",
       "1   we cannot see the wind but we can feel it . t...   \n",
       "2   yesterday it rained . there was a lot of wind...   \n",
       "3   summer is here ! july is sunny and hot . summ...   \n",
       "4   it 's starting to cool down from the summer h...   \n",
       "5   the wind pushes the kite high into the sky . ...   \n",
       "\n",
       "                                            text_org  \n",
       "1   We cannot see the wind but we can feel it. Th...  \n",
       "2   Yesterday it rained. There was a lot of wind....  \n",
       "3   Summer is here! July is sunny and hot. Summer...  \n",
       "4   It's starting to cool down from the summer he...  \n",
       "5   The wind pushes the kite high into the sky. W...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' We cannot see the wind but we can feel it. The wind makes the trees move. We can see the branches and leaves moving. We can hear the wind rustling, or moving the leaves.',\n",
       "       ' Yesterday it rained. There was a lot of wind. It was not safe to go out and play. The rain was good for the Earth. Rain helps the trees and flowers grow.',\n",
       "       ' Summer is here! July is sunny and hot. Summer can have a lot of rain too. Which type of weather do you like best?',\n",
       "       ...,\n",
       "       ' Calculate the average power output of this generator. (6 marks) [TOTAL: 12 marks] SOLUTION Question 1 1. Electrical (energy) to mechanical (kinetic) energy 2. Mechanical (kinetic) energy to electrical (energy) 3. Motor effect 4. Electromagnetic induction (4 marks) Question 2 BC (conductor) is parallel to the magnetic field.',\n",
       "       ' Open switch, no current (2 marks) Question 3 Option 1: Pave = VrmsIrms Option 2: Vmax Vmax Imax Vrms = 2 = 2 2 (311)(21) = 2 = 219,91 V = 3265,5 W Pmax = VmaxImax = (311)(21) = 6531 W Pave = Pmax = 6531 = 3265,5 W Imax Irms = 2 = 14,85 A Pave = VrmsIrms = (219,91)(14,85) = 3265,66 W See presentation: 27YS at  Electrical generators convert mechanical energy into electrical energy. Electric motors convert electrical energy into mechanical energy. There are two types of generators AC and DC. An AC generator is also called an alternator. There are two types of motors AC and DC. Alternating current (AC) has many advantages over direct current (DC) listed previously. The root mean square(rms) value of a quantity is the maximum value the quantity can have divided by 2. RMS values are used for voltage and current when dealing with alternating current, Irms = Imax 2 and Vrms = Vmax The average power dissipated in a purely resistive circuit with alternating current is Pav = Irms Vrms .',\n",
       "       ' Exercise 11 3: 1. [SC 2003/11] Explain the difference between alternating current (AC) and direct current (DC). 2. Explain how an AC generator works. You may use sketches to support your answer. 3. What are the advantages of using an AC motor rather than a DC motor. 4. Explain how a DC motor works. 5. At what frequency is AC generated by Eskom in South Africa? 6. (IEB 2001/11 HG1) Work, Energy and Power in Electric Circuits Mr. Smith read through the agreement with Eskom (the electricity provider). He found out that alternating current is supplied to his house at a frequency of 50 Hz. He then consulted a book on electric current, and discovered that alternating current moves to and fro in the conductor. So he refused to pay his Eskom bill on the grounds that every electron that entered his house would leave his house again, so therefore Eskom had supplied him with nothing! Was Mr. Smith correct? Or has he misunderstood something about what he is paying for? Explain your answer briefly. 7. You are building a laser that takes alternating current and it requires a very high peak voltage of 180 kV. By your calculations the entire laser setup can be treated at a single resistor with an equivalent resistance of 795 ohms. What is the rms value for the voltage and the current and what is the average power that your laser is dissipating?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all['text_org'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" 6 Gregor Mendel and the Foundations of Genetics Lesson Objectives Explain Mendel's law of segregation. Draw a Punnett square to make predictions about the traits of the offspring of a simple genetic cross.\"\n",
      " \" 2. How did Jefferson's strict constructionist interpretation of the Constitution impede his plan to acquire additional U territory?\"\n",
      " ' Further Reading / Supplemental Links Mark Pagel, ed. The Oxford Encyclopedia of Evolution. New York: Oxford University Press, 2002.'\n",
      " ' CHAPTER 20. THE HYDROSPHERE GRADE 10 20 1. Carbon dioxide Carbon dioxide reacts with water in the atmosphere to form carbonic acid (H2CO3).'\n",
      " ' 4. How do the rights and responsibilities expressed in the Constitution balance tensions between personal rights and responsibilities as well as individual rights and the common good?']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# RANDOMLY SAMPLE 100\n",
    "random.seed(123)\n",
    "to_annotate = random.sample(range(len(d_all['text_org'].values)), 100)\n",
    "text_to_annotate = d_all['text_org'].values[to_annotate]\n",
    "print(text_to_annotate[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(text_to_annotate):\n",
    "    outfile_name = ('/Users/yuling/desktop/brat-master/data/TEXTBOOK/F_M_N_mentions/F_M_N_%d.txt' % (i+1))\n",
    "    with open(outfile_name, 'w', newline='') as f_output:\n",
    "        f_output.write(text_to_annotate[i].strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample gendered mentions to label (for coref and nel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gendered\n",
    "df_gendered = pd.read_csv('textbook_data/gendered.csv', delimiter= \",\", low_memory=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" Chapter 8 MS Prokaryotes The above image shows bacteria dyed with a fluorescent color. They look just like little cells. Well, that's exactly what they are. Bacteria are prokaryotic organisms. About 3 billion years ago, long before the first plants, people, or other animals appeared, prokaryotes were the first life forms on Earth. For at least a billion years, prokaryotes ruled the Earth as the only existing organisms. What do you think of when you think of bacteria? Germs? Diseases? Bacteria can be harmful, but they can also help you. How do you think bacteria can help humans and other organisms? Did you know that bacteria are not the only type of prokaryote? There is another type, called archaea, which we will explore in addition to the questions asked above.\"\n",
      " ' Online Interactive Activities Use the following interactive to explore half-life and to find the age of several objects:  This interactive allows you to look at how the number of radioactive isotopes present changes over time. As you work through the interactive:  , look for the following: How could you find the half-life of each isotope? How come some isotopes have really long isotopes and others have longer half-lifes? How does the number of parent (reactant) atoms change over time? How does the number of daughter (product) atoms change over time?'\n",
      " ' Further Reading / Supplemental Links Mark Pagel, ed. The Oxford Encyclopedia of Evolution. New York: Oxford University Press, 2002. Stephen Jay Gould, ed. The Book of Life: An Illustrated History of the Evolution of Life on Earth. New York: W Norton, 1993. Colleen Whitney, Kate Barton, David Smith, The Paleontology Portal. University of California Museum of Paleontology, Paleontological Society, Society of Vertebrate Paleontology, and US Geological Survey, 2003. Available on the Web at:  Continental Drift Animation. EduMedia-sciences, 2002-2007 on the Web at:  Dave Smith, Life Has a History Level 2. University of California Museum of Paleontology, 7/18/06. Available on the Web at:  tour1 David Ulansey, The Current Mass Extinction. David Ulansey, last updated 3 July 2007. Available on the Web at:  Lexi Krock, The Missing Link: A Brief History of Life. Nova Online, last updated February 2002. Available on the Web at:  Richard Cowen, History of Life, 4th edition Updates, References and weblinks. UC Davis Geology Department, 3 March 2006. Available on the Web at:  Roger Perkins, The Virtual Fossil Museum: Fossils across Geologic Time and Evolution. Available on the Web at:  Roy Caldwell and David Lindberg, Understanding Evolution. University of California Museum of Paleontology, 2007. Available on the Web at:  Vocabulary Archaeopteryx One of the most famous transition fossils; has characteristics of both reptiles and birds.'\n",
      " \"  Although Taft was physically a large man at six feet tall and 350 pounds, he did not have the same larger-than-life personality that Roosevelt possessed. This was evidenced by the sheer number of the 90 trusts he busted in his four year term compared to Roosevelt's 44 trusts over a seven year period. He was cautious in his pursuit of the progressive agenda eliminating Roosevelt's distinction between good trusts and bad trusts and hesitated to take advantage of the presidential bully pulpit in the way that was Roosevelt's trademark. He unsuccessfully tried to strike a balance between the conservatives and progressives in his party which Roosevelt had managed to hold together through the sheer force of his personality. Progressives were particularly angry with him over tariffs and conservation. Taft had campaigned on the promise to lower tariffs. This was a fundamental issue for progressives because high tariffs benefited businesses at the expense of consumers. All went according to plan in the House of Representatives where they passed the Payne bill which lowered tariffs on many manufactured goods. Conservative Republicans in the Senate, however, eliminated most of the cuts in their version. Progressives, including Roosevelt, felt betrayed when President Taft signed the PayneAldrich Tariff. He only made matters worse when he referred to it as the the best [tariff] bill the Republican party ever passed in his attempts to defend it.\"\n",
      " ' Daniel Fahrenheit established the Fahrenheit scale. On his temperature scale, Fahrenheit designated the freezing point of water as 32F and the boiling point of water as 212F. Therefore, the distance between these two points would be divided into 180 degrees. The Fahrenheit temperature scale is used in the United States for most daily expressions of temperature. In another temperature scale, scientist Anders Celsius designated the freezing point of water as 0C and the boiling point of water as 100C. Therefore, the temperatures between these two points on the Celsius scale are divided into 100. Clearly, the size of a Celsius degree and the size of a Fahrenheit degree are not the same.']\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "to_annotate_gendered = random.sample(range(len(df_gendered['text'].values)), 300)\n",
    "text_to_annotate_gendered = df_gendered['text'].values[to_annotate_gendered]\n",
    "print(text_to_annotate_gendered[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(text_to_annotate_gendered):\n",
    "    outfile_name = ('/Users/yuling/desktop/brat-master/data/TEXTBOOK/Coref_NEL_mentions/Coref_NEL_%d.txt' % (i+1))\n",
    "    with open(outfile_name, 'w', newline='') as f_output:\n",
    "        f_output.write(text_to_annotate_gendered[i].strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-cubed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dict = {\n",
    "    \"item1\": [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\"],\n",
    "    \"item2\": [\"B1\", \"B2\"],\n",
    "    \"item3\": [\"C1\", \"C2\"],\n",
    "}\n",
    "\n",
    "system_out_dict = {\n",
    "    \"item1\": [\"A1\", \"A2\", \"A3\", \"B2\"],\n",
    "    \"item2\": [\"A4\", \"A5\", \"A6\"],\n",
    "    \"item3\": [\"B1\"],\n",
    "    \"item4\": [\"C1\"],\n",
    "    \"item5\": [\"C2\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links(cdict):\n",
    "    all_links = []\n",
    "    all_links_by_mention = []\n",
    "    for person_cluster in cdict:\n",
    "        cluster = cdict[person_cluster]\n",
    "        all_person = list(cluster)\n",
    "        #print(all_person)\n",
    "        for mention in all_person:\n",
    "            mention_based = []\n",
    "            for other_mention in all_person:\n",
    "                #print((mention,other_mention), end = \"\")\n",
    "                all_links.append((mention,other_mention))\n",
    "                mention_based.append((mention,other_mention))\n",
    "            #print()\n",
    "            all_links_by_mention.append(mention_based)\n",
    "        #print()\n",
    "    return all_links, all_links_by_mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_answer, links_by_mention_answer = get_all_links(answer_dict)\n",
    "links_output, links_by_mention_output = get_all_links(system_out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = [link for link in links_answer if link in links_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_score(precision, recall):\n",
    "    return (2 * precision * recall)/ (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-cubed, average metric\n",
      "Precision :  0.7857142857142857\n",
      "Recall :  0.5\n",
      "F-score :  0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "print(\"B-cubed, average metric\")\n",
    "precision = len(overlap)/len(links_output)\n",
    "recall = len(overlap)/len(links_answer)\n",
    "print(\"Precision : \", precision)\n",
    "print(\"Recall : \", recall)\n",
    "print(\"F-score : \",  get_f_score(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_mention_links = {links[0][0]: links for links in links_by_mention_answer}\n",
    "output_mention_links = {links[0][0]: links for links in links_by_mention_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_macro(answer_mention_links, output_mention_links, get_score):\n",
    "    '''\n",
    "    get_socre : \"precision\" or \"recall\"\n",
    "    '''\n",
    "    \n",
    "    if get_score == \"recall\":\n",
    "        links1 = answer_mention_links\n",
    "        links2 = output_mention_links\n",
    "    elif get_score == \"precision\":\n",
    "        links1 = output_mention_links\n",
    "        links2 = answer_mention_links\n",
    "    else:\n",
    "        print(\"Indicate precision or recall!\")\n",
    "        return \n",
    "    \n",
    "    score = 0\n",
    "    for mention in links1:\n",
    "        # print(mention)\n",
    "        mention_links = links1[mention]\n",
    "        if mention in links2:\n",
    "            compare_links =  links2[mention]\n",
    "            correct_links = [link for link in mention_links if link in compare_links]\n",
    "            score += len(correct_links)/len(mention_links)\n",
    "        else:\n",
    "            score += 0\n",
    "    return score/len(links1), score, len(links1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-cubed, mention-based approach\n",
      "Precision :  0.85\n",
      "Recall :  0.5\n",
      "F-score :  0.6296296296296295\n"
     ]
    }
   ],
   "source": [
    "recall_macro = get_precision_recall_macro(answer_mention_links, output_mention_links, \"recall\")\n",
    "precision_macro = get_precision_recall_macro(answer_mention_links, output_mention_links, \"precision\")\n",
    "print(\"B-cubed, mention-based approach\")\n",
    "print(\"Precision : \", precision_macro)\n",
    "print(\"Recall : \", recall_macro)\n",
    "print(\"F-score : \",  get_f_score(precision_macro, recall_macro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated May 31: Start looking from here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-cubed with list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_idx = [[[8, 8], [15, 15], [28, 28]], [[62, 62], [73, 74], [74, 74]], [[96, 96], [102, 102]]]\n",
    "answer_str = [['bacteria', 'They', 'they'], ['Earth', 'the Earth', 'Earth'], ['Bacteria', 'they']]\n",
    "output_idx = [[[8, 8], [28, 28]], [[62, 62], [73, 74], [74, 74]], [[96, 96]]]\n",
    "output_str = [['bacteria', 'they'], ['Earth', 'the Earth', 'Earth'], ['Bacteria']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_idx_str(list_idx, list_str):\n",
    "    cluster_w_idx = [[(word, cluster[1][i]) for i, word in enumerate(cluster[0])] for cluster in tuple(zip(list_str, list_idx))]\n",
    "    return cluster_w_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_cluster = merge_idx_str(answer_idx, answer_str)\n",
    "output_cluster = merge_idx_str(output_idx, output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('bacteria', [8, 8]), ('They', [15, 15]), ('they', [28, 28])],\n",
       " [('Earth', [62, 62]), ('the Earth', [73, 74]), ('Earth', [74, 74])],\n",
       " [('Bacteria', [96, 96]), ('they', [102, 102])]]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is like what the functions below get from neuralcoref and allennlp\n",
    "answer_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links(cluster_list):\n",
    "    all_links = []\n",
    "    all_links_by_mention = []\n",
    "    for all_person in cluster_list:\n",
    "        #print(all_person)\n",
    "        for mention in all_person:\n",
    "            mention_based = []\n",
    "            for other_mention in all_person:\n",
    "                #print((mention,other_mention), end = \"\")\n",
    "                all_links.append((mention,other_mention))\n",
    "                mention_based.append((mention,other_mention))\n",
    "            #print()\n",
    "            all_links_by_mention.append(mention_based)\n",
    "        #print()\n",
    "    return all_links, all_links_by_mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_answer, links_by_mention_answer = get_all_links(answer_cluster)\n",
    "links_output, links_by_mention_output = get_all_links(output_cluster)\n",
    "answer_mention_links = {str(links[0][0]): links for links in links_by_mention_answer}\n",
    "output_mention_links = {str(links[0][0]): links for links in links_by_mention_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_macro(answer_mention_links, output_mention_links, get_score):\n",
    "    '''\n",
    "    get_socre : \"precision\" or \"recall\"\n",
    "    '''\n",
    "    \n",
    "    if get_score == \"recall\":\n",
    "        links1 = answer_mention_links\n",
    "        links2 = output_mention_links\n",
    "    elif get_score == \"precision\":\n",
    "        links1 = output_mention_links\n",
    "        links2 = answer_mention_links\n",
    "    else:\n",
    "        print(\"Indicate precision or recall!\")\n",
    "        return \n",
    "    \n",
    "    score = 0\n",
    "    correct_cnt = 0 \n",
    "    total_cnt = 0\n",
    "    for mention in links1:\n",
    "        # print(mention)\n",
    "        mention_links = links1[mention]\n",
    "        if mention in links2:\n",
    "            compare_links =  links2[mention]\n",
    "            correct_links = [link for link in mention_links if link in compare_links]\n",
    "            score += len(correct_links)/len(mention_links)\n",
    "            correct_cnt += len(correct_links)\n",
    "            total_cnt += len(mention_links)\n",
    "        else:\n",
    "            total_cnt += len(mention_links)\n",
    "    return score/len(links1), correct_cnt, total_cnt\n",
    "\n",
    "def get_f_score(precision, recall):\n",
    "    return (2 * precision * recall)/ (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-cubed, mention-based approach\n",
      "Precision :  1.0\n",
      "Recall :  0.6041666666666666\n",
      "F-score :  0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "recall, tp, tp_fn = get_precision_recall_macro(answer_mention_links, output_mention_links, \"recall\")\n",
    "precision, tp, tp_fp = get_precision_recall_macro(answer_mention_links, output_mention_links, \"precision\")\n",
    "print(\"B-cubed, mention-based approach\")\n",
    "print(\"Precision : \", precision)\n",
    "print(\"Recall : \", recall)\n",
    "print(\"F-score : \",  get_f_score(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "macro_avg_numerator_precision = 0\n",
    "macro_avg_numerator_recall = 0\n",
    "macro_avg_denominator = 300 # just the num of para\n",
    "micro_avg_numerator = 0\n",
    "micro_avg_denominator_recall = 0\n",
    "micro_avg_denominator_precision = 0\n",
    "for annotation in 300 paras:\n",
    "    parse system output and annotation as above\n",
    "    recall, tp1, tp_fn = get_precision_recall_macro(answer_mention_links, output_mention_links, \"recall\")\n",
    "    precision, tp2, tp_fp = get_precision_recall_macro(answer_mention_links, output_mention_links, \"precision\")\n",
    "    assert tp1 == tp2\n",
    "    # macro-avg\n",
    "    macro_avg_numerator_precision += precision\n",
    "    macro_avg_numerator_recall += recall\n",
    "    \n",
    "    # micro-avg\n",
    "    micro_avg_numerator += tp1\n",
    "    micro_avg_denominator_recall += tp_fn\n",
    "    micro_avg_denominator_precision += tp_fp\n",
    "    \n",
    "\n",
    "macro_precision = macro_avg_numerator_precision/ macro_avg_denominator\n",
    "macro_recall = macro_avg_numerator_recall/ macro_avg_denominator\n",
    "\n",
    "mirco_precision = micro_avg_numerator/micro_avg_denominator_precision\n",
    "micro_recall = micro_avg_numerator/micro_avg_denominator_recall\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralCoref track character indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Eva and Martha didn't want their friend Jenny to feel lonely so they invited her to the party. Tom is happy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to extend to multi sentence, rn doesnt track \"Tom is happy\"\n",
    "def get_cluster_neuralcoref(text):\n",
    "    doc = nlp(text)\n",
    "    all_clusters = []\n",
    "    for cluster in doc._.coref_clusters:\n",
    "        cluster_mentions = []\n",
    "        for mention in cluster.mentions:\n",
    "            cluster_mentions.append((mention.text, [mention.start_char, mention.end_char]))\n",
    "        all_clusters.append(cluster_mentions)\n",
    "    return all_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_cluster_neuralcoref(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AllenNLP track character indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_allennlp(text):\n",
    "    text_idx = [[word.text, word.idx, word.idx + len(word)] for word in nlp(text)]\n",
    "    prediction = allen_predictor.predict_tokenized([word.text for word in nlp(text)])\n",
    "    all_clusters = []\n",
    "    for cluster in prediction['clusters']:\n",
    "        cluster_mentions = []\n",
    "        for token in cluster:\n",
    "            token_idx_start = token[0]\n",
    "            token_idx_end = token[1]\n",
    "            if len(text_idx[token_idx_start: token_idx_end + 1]) > 1:\n",
    "                #text_mention = \" \".join([word[0] for word in text_idx[token_idx_start: token_idx_end + 1]])\n",
    "                start = text_idx[token_idx_start][1]\n",
    "                end = text_idx[token_idx_end][2]\n",
    "                text_mention = text[start : end]\n",
    "                text_start_end = [text_mention, start, end]\n",
    "            else:\n",
    "                text_start_end = text_idx[token_idx_start: token_idx_end + 1][0]\n",
    "            cluster_mentions.append((text_start_end[0], [text_start_end[1], text_start_end[2]]))\n",
    "        all_clusters.append(cluster_mentions)\n",
    "    return all_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_cluster_allennlp(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
