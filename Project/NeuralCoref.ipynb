{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EE517: Project NeuralCoref.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nXSx0jEDC_Kg",
        "t7EpasiPPksV",
        "JHgdBEuSPfhr",
        "rHxHvquJPksX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darisoy/EE517_Sp21/blob/master/Project/NeuralCoref.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv6GGyImBLGy"
      },
      "source": [
        "# Set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ygH8OIYeUub"
      },
      "source": [
        "# install packages\n",
        "%%capture\n",
        "!pip install spacy==2.2.4\n",
        "!python -m spacy download en\n",
        "!venv .env\n",
        "!source .env/bin/activate\n",
        "!git clone https://github.com/huggingface/neuralcoref.git\n",
        "!pip install -r /content/neuralcoref/requirements.txt\n",
        "!pip install -e /content/neuralcoref/\n",
        "\n",
        "!pip install gender-guesser\n",
        "!git clone https://github.com/darisoy/EE517_Sp21.git\n",
        "!pip install bcubed\n",
        "!pip install pyspotlight"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZlVlbT4UvLC"
      },
      "source": [
        "import bcubed\n",
        "import pandas as pd\n",
        "import gender_guesser.detector as gender\n",
        "from tqdm.notebook import tqdm\n",
        "import spotlight"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khMWzWyQiB32"
      },
      "source": [
        "# load models\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "import neuralcoref\n",
        "# restart runtime if this throws an error\n",
        "coref = neuralcoref.NeuralCoref(nlp.vocab)\n",
        "nlp.add_pipe(coref, name='neuralcoref')\n",
        "genDec = gender.Detector()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH72BvHVdHYY"
      },
      "source": [
        "# list of person mentions that are not names\n",
        "fem_p = ['she', 'her', 'hers', 'herself']\n",
        "male_p = ['he', 'him', 'his', 'himself']\n",
        "personal_p = ['i', 'me', 'we', 'us', 'myself', 'ourself', 'ourselves']\n",
        "other_p = ['they', 'them', 'their', 'you', 'themself', 'themselves']\n",
        "people = ['adult','adults', 'person','people','child','children']\n",
        "\n",
        "person_f_singular = ['girl','woman','mrs','ms','mother','mom','aunt','niece','sister','wife','daughter','grandmother','grandma','grandmom','granddaughter','bride','girlfriend','gal','madam','lady']\n",
        "person_m_singular = ['boy','man','mr','father','dad','uncle','nephew','brother','husband','son','grandfather','grandpa','granddad','grandson','groom','boyfriend','guy','gentleman','bachelor']\n",
        "people_f_plural = ['girls','women','mothers','moms','aunts','nieces','sisters','wives','daughters','grandmothers','grandmas','granddaughters','brides','girlfriends','gals','ladies']\n",
        "people_m_plural = ['boys','men','fathers','dads','uncles','nephews','brothers','husbands','sons','grandfathers','grandpas','grandsons','grooms','boyfriends','guys','gentlemen','bachelors']\n",
        "people_f = person_f_singular + people_f_plural\n",
        "people_m = person_m_singular + people_m_plural\n",
        "\n",
        "un_named_mentions = fem_p + male_p + personal_p + other_p + people + people_f + people_m\n",
        "f_un_named = fem_p + people_f\n",
        "m_un_named = male_p + people_m\n",
        "gendered_un_named = f_un_named + m_un_named\n",
        "neutral_un_named = personal_p + other_p + people"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRwvwsFddJ5J"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNv3pglGdL_J"
      },
      "source": [
        "# run text through models\n",
        "\n",
        "def get_coref(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    dic = [t.text for t in doc]\n",
        "    coref = [[[ent.start, ent.end-1] for ent in cluster.mentions] for cluster in doc._.coref_clusters]\n",
        "    return coref, dic\n",
        "\n",
        "def get_ner(text, nlp):\n",
        "    return [[ent.start, ent.end-1] for ent in nlp(text).ents if ent.label_ == 'PERSON']\n",
        "\n",
        "def get_nel(text):\n",
        "    threshold = 0.95\n",
        "    results = spotlight.annotate('https://api.dbpedia-spotlight.org/en/annotate', text, confidence=threshold)\n",
        "    return [p['surfaceForm'] for p in results if 'Person' in p['types']]\n",
        "\n",
        "def get_gender(person_mention):\n",
        "    if person_mention.lower() in gendered_un_named:\n",
        "        if person_mention.lower() in f_un_named:\n",
        "            return 'F'\n",
        "        elif person_mention.lower() in m_un_named:\n",
        "            return 'M'\n",
        "    elif len(person_mention) > 0:\n",
        "        first_name = person_mention.split()[0]\n",
        "        gen_name = genDec.get_gender(first_name.capitalize())\n",
        "        if 'female' in gen_name:\n",
        "            return 'F'\n",
        "        elif 'male' in gen_name:\n",
        "            return 'M'\n",
        "    return '-'\n",
        "\n",
        "def get_pronouns(dic):\n",
        "    result = []\n",
        "    for i, word in enumerate(dic):\n",
        "        if word.lower() in gendered_un_named:\n",
        "            result.append([i, i])\n",
        "    return result"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUw_5ZqajaeD"
      },
      "source": [
        "# converting spans to text\n",
        "\n",
        "def span_to_string(span, dic):\n",
        "    [a, b] = span\n",
        "    return \" \".join(dic[a:b+1])\n",
        "\n",
        "def array_to_text(array, dic):\n",
        "    return [span_to_string(e, dic) for e in array]\n",
        "\n",
        "def array2d_to_text(array2D, dic):\n",
        "    return [array_to_text(arr, dic) for arr in array2D]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJcG7OAXjdKd"
      },
      "source": [
        "# get hypo & histo from model results\n",
        "\n",
        "def get_cluster(person, clusters):\n",
        "    for i, cluster in enumerate(clusters):\n",
        "        if person in cluster:\n",
        "            return clusters[i]\n",
        "    return [person]\n",
        "\n",
        "def split_hist_hypo(clusters, person_mentions, famous_people, gender, dic):\n",
        "    historical = []\n",
        "    hypothetical = []\n",
        "    hist_genders = []\n",
        "    hypo_genders = []\n",
        "    for i, person in enumerate(person_mentions):\n",
        "        # skip if not gendered\n",
        "        if gender[i] == '-':\n",
        "            continue\n",
        "        # skip if already in one of the lists\n",
        "        in_historical = any(person in sublist for sublist in historical)\n",
        "        in_hypothetical = any(person in sublist for sublist in hypothetical)\n",
        "        if in_historical or in_hypothetical:\n",
        "            continue\n",
        "        # add the cluster to correct list\n",
        "        person_set = get_cluster(person, clusters)\n",
        "        if any(p in array_to_text(person_set, dic) and p in array_to_text(person_mentions, dic) for p in famous_people):\n",
        "            historical.append(person_set)\n",
        "            hist_genders.append(gender[i])\n",
        "        else:\n",
        "            hypothetical.append(person_set)\n",
        "            hypo_genders.append(gender[i])\n",
        "    return historical, hist_genders, hypothetical, hypo_genders"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMVgkpXZjjr_"
      },
      "source": [
        "# pipline for a single given text\n",
        "def get_hist_hypo_references(text, nlp, debug=False):\n",
        "    doc = nlp(text)\n",
        "    clusters, dic = get_coref(text, nlp)\n",
        "    person_mentions = get_ner(text, nlp) + get_pronouns(dic)\n",
        "    gender = [get_gender(span_to_string(p, dic)) for p in person_mentions]\n",
        "    famous_people = get_nel(text)\n",
        "    hist, hist_g, hypo, hypo_g = split_hist_hypo(clusters, person_mentions, famous_people, gender, dic)\n",
        "    hist_str = array2d_to_text(hist, dic)\n",
        "    hypo_str = array2d_to_text(hypo, dic)\n",
        "    if debug and len(person_mentions) > 0:\n",
        "        print('***NEW SENTENCE***\\t\\t %s' % text)\n",
        "        print()\n",
        "        print('Coreference Model Output\\t %s' % array2d_to_text(clusters, dic))\n",
        "        print('NER + Pronouns Output\\t\\t %s' % array_to_text(person_mentions, dic))\n",
        "        print('Gender Guesser Output\\t\\t %s' % gender)\n",
        "        print('NEL Output\\t\\t\\t %s' % famous_people)\n",
        "        print()\n",
        "        print('Historical references\\t\\t %s' % hist_str)\n",
        "        print('Historical genders\\t\\t %s' % hist_g)\n",
        "        print('Hypothetical references\\t\\t %s' % hypo_str)\n",
        "        print('Hypothetical genders\\t\\t %s' % hypo_g)\n",
        "        print()\n",
        "        print()\n",
        "    return hist, hist_g, hypo, hypo_g, dic, famous_people"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNj_VGojjmQS"
      },
      "source": [
        "# dictinories for evaluations\n",
        "\n",
        "def get_pipe_dic(text, nlp):\n",
        "    gendered_clusters, dic = get_references(text, nlp)\n",
        "    pipe_dic = {}\n",
        "    for i, cluster in enumerate(array2d_to_text(gendered_clusters, dic)):\n",
        "        pipe_dic['Person%d' % (i+1)] = set(cluster)\n",
        "    return pipe_dic\n",
        "\n",
        "def get_ann_dic(file):\n",
        "    ann_dic = {}\n",
        "    for line in file:\n",
        "        tabs = line.split('\\t')\n",
        "        key = tabs[1].split()[0]\n",
        "        if len(tabs) < 3 or key == \"InDatabase\":\n",
        "            continue\n",
        "        value = tabs[2]\n",
        "        if value[-1] == '\\n':\n",
        "            value = value[:-1]\n",
        "        if key in ann_dic.keys():\n",
        "            current_set = ann_dic[key]\n",
        "            current_set.add(value)\n",
        "            ann_dic.update({ key: current_set})\n",
        "        else:\n",
        "            ann_dic.update({ key: set([value])})\n",
        "    return ann_dic"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57vMJyWAb_5_",
        "outputId": "79fdb5a4-6ba6-429a-da5a-153ba6395312"
      },
      "source": [
        "sample = 'Isaac Newton invented the wheel. He didn\\'t go to kindergarden but he was familiar with circles. When told this story, Jessica didn\\'t believe it. She thought Newton was a lie.'\n",
        "hist, hist_g, hypo, hypo_g, dic, database = get_hist_hypo_references(sample, nlp, debug=True)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***NEW SENTENCE***\t\t Isaac Newton invented the wheel. He didn't go to kindergarden but he was familiar with circles. When told this story, Jessica didn't believe it. She thought Newton was a lie.\n",
            "\n",
            "Coreference Model Output\t [['Isaac Newton', 'He', 'he', 'Newton'], ['this story', 'it'], ['Jessica', 'She']]\n",
            "NER + Pronouns Output\t\t ['Isaac Newton', 'Jessica', 'Newton', 'He', 'he', 'She']\n",
            "Gender Guesser Output\t\t ['M', 'F', 'M', 'M', 'M', 'F']\n",
            "NEL Output\t\t\t ['Isaac Newton', 'Newton']\n",
            "\n",
            "Historical references\t\t [['Isaac Newton', 'He', 'he', 'Newton']]\n",
            "Historical genders\t\t ['M']\n",
            "Hypothetical references\t\t [['Jessica', 'She']]\n",
            "Hypothetical genders\t\t ['F']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt2kAuCR3JH4",
        "outputId": "92ea838b-0dba-4e83-aa12-721797b74324"
      },
      "source": [
        "get_nel(sample)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Isaac Newton', 'Newton']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNMdWlCFmEOJ"
      },
      "source": [
        "## Coref evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwh2d7IlmErF"
      },
      "source": [
        "for i in tqdm(range(300)):\n",
        "    text_file = \"/content/EE517_Sp21/Project/Coref_NEL_mentions/Coref_NEL_%d.txt\" % (i+1)\n",
        "    ann_file = \"/content/EE517_Sp21/Project/Coref_NEL_mentions/Coref_NEL_%d.ann\" % (i+1)\n",
        "    text = open(text_file, 'r').readline()\n",
        "    \n",
        "    pipe_dic = get_pipe_dic(text, nlp)\n",
        "    ann_dic = get_ann_dic(open(ann_file, 'r'))\n",
        "\n",
        "    max_len = max(len(pipe_dic), len(ann_dic))\n",
        "    i = len(pipe_dic)\n",
        "    while len(pipe_dic) < max_len:\n",
        "        key = \"Person%d\" % i\n",
        "        pipe_dic.update({ key: set([]) })\n",
        "        i += 1\n",
        "    i = len(ann_dic)\n",
        "    while len(ann_dic) < max_len:\n",
        "        key = \"Person%d\" % i\n",
        "        ann_dic.update({ key: set([]) })\n",
        "        i += 1\n",
        "\n",
        "    print(len(pipe_dic))\n",
        "    print(len(ann_dic))\n",
        "\n",
        "    precision = bcubed.precision(pipe_dic, ann_dic)\n",
        "    recall = bcubed.recall(pipe_dic, ann_dic)\n",
        "    fscore = bcubed.fscore(precision, recall)\n",
        "    print(\"Precision: %.3f\\tRecall: %.3f\\tFscore: %.3f\" % (precision, recall, fscore))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FobdLSwumUv3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}